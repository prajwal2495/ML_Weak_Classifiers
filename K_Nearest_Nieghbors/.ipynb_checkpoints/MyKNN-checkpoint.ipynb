{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class my_KNN:\n",
    "\n",
    "    def __init__(self, n_neighbors=5, metric=\"minkowski\", p=2):\n",
    "        # metric = {\"minkowski\", \"euclidean\", \"manhattan\", \"cosine\"}\n",
    "        # p value only matters when metric = \"minkowski\"\n",
    "        # notice that for \"cosine\", 1 is closest and -1 is furthest\n",
    "        # therefore usually cosine_dist = 1- cosine(x,y)\n",
    "        self.n_neighbors = int(n_neighbors)\n",
    "        self.metric = metric\n",
    "        self.p = p\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # X: pd.DataFrame, independent variables, float\n",
    "        # y: list, np.array or pd.Series, dependent variables, int or str\n",
    "        self.classes_ = list(set(list(y)))\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "#         for x in X[self.X.columns]:\n",
    "#             print(x)\n",
    "#         #print(X[self.X.columns])\n",
    "\n",
    "#         for x_next in self.X:\n",
    "#             print(x_next)\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "    \n",
    "    def minkowski_distance(self, x1, x2):\n",
    "        return np.sum(((np.absolute(x1 - x2)) ** self.p)) ** 1/self.p\n",
    "    \n",
    "    def manhattan_distance(self, x1, x2):\n",
    "        return np.sum(np.absolute(x1 - x2)) #+ np.absolute(x1[1] + x2[1]))\n",
    "    \n",
    "    def cosine_distance(self, x1, x2):\n",
    "        numerator = np.dot(x1,x2)\n",
    "        denominator_x1 = np.sqrt(np.sum(x1 ** 2))\n",
    "        denominator_x2 = np.sqrt(np.sum(x2 ** 2))\n",
    "        return 1 - (numerator / (denominator_x1 * denominator_x2))\n",
    "#         return spatial.distance.cosine(x1,x2)\n",
    "        \n",
    "        #return (np.dot(x1 , x2) / (np.abs(x1) * np.abs(x2)))\n",
    "#         up = np.dot(x1,x2)\n",
    "#         down = np.sum((np.absolute(x1)**2) * (np.absolute(x2)**2))\n",
    "#         return up/down\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "    def dist(self,x):\n",
    "        # Calculate distances of training data to a single input data point (np.array)\n",
    "        \n",
    "        if self.metric == \"minkowski\":\n",
    "            X_cols_vals = self.X[self.X.columns]\n",
    "            distances = [self.minkowski_distance(x, x_next) for x_next in X_cols_vals.to_numpy()]\n",
    "            #distances = \"write your own code\"\n",
    "\n",
    "\n",
    "        elif self.metric == \"euclidean\":\n",
    "            X_cols_vals = self.X[self.X.columns]\n",
    "            distances = [self.euclidean_distance(x, x_next) for x_next in X_cols_vals.to_numpy()]\n",
    "\n",
    "        elif self.metric == \"manhattan\":\n",
    "            X_cols_vals = self.X[self.X.columns]\n",
    "            distances = [self.manhattan_distance(x, x_next) for x_next in X_cols_vals.to_numpy()]\n",
    "            #distances = \"write your own code\"\n",
    "\n",
    "\n",
    "        elif self.metric == \"cosine\":\n",
    "            X_cols_vals = self.X[self.X.columns]\n",
    "            distances = [self.cosine_distance(x, x_next) for x_next in X_cols_vals.to_numpy()]\n",
    "            #distances = \"write your own code\"\n",
    "            \n",
    "        else:\n",
    "            raise Exception(\"Unknown criterion.\")\n",
    "            \n",
    "        return distances\n",
    "\n",
    "    def k_neighbors(self,x):\n",
    "        # Return the stats of the labels of k nearest neighbors to a single input data point (np.array)\n",
    "        # Output: Counter(labels of the self.n_neighbors nearest neighbors)\n",
    "        \n",
    "        distances = self.dist(x)\n",
    "        indices_of_k = np.argsort(distances)[:self.n_neighbors]\n",
    "        k_nearest_labels = [self.y[i] for i in indices_of_k]\n",
    "        output = Counter(k_nearest_labels)\n",
    "        #print(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def predict(self, X):\n",
    "        # X: pd.DataFrame, independent variables, float\n",
    "        # return predictions: list\n",
    "        probs = self.predict_proba(X)\n",
    "        predictions = [self.classes_[np.argmax(prob)] for prob in probs.to_numpy()]\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # X: pd.DataFrame, independent variables, float\n",
    "        # prob is a dict of prediction probabilities belonging to each categories\n",
    "        # return probs = pd.DataFrame(list of prob, columns = self.classes_)\n",
    "        probs = []\n",
    "        try:\n",
    "            X_feature = X[self.X.columns]\n",
    "        except:\n",
    "            raise Exception(\"Input data mismatch.\")\n",
    "        \n",
    "        #print(X_feature)\n",
    "\n",
    "        for x in X_feature.to_numpy():\n",
    "            #print(x)\n",
    "            neighbors = self.k_neighbors(x)\n",
    "            probs.append({key: neighbors[key] / float(self.n_neighbors) for key in self.classes_})\n",
    "        probs = pd.DataFrame(probs, columns=self.classes_)\n",
    "        \n",
    "        return probs\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-setosa\t1.000000\n",
      "Iris-setosa\t1.000000\n",
      "Iris-setosa\t1.000000\n",
      "Iris-setosa\t1.000000\n",
      "Iris-setosa\t1.000000\n",
      "Iris-versicolor\t1.000000\n",
      "Iris-versicolor\t1.000000\n",
      "Iris-versicolor\t1.000000\n",
      "Iris-versicolor\t1.000000\n",
      "Iris-versicolor\t1.000000\n",
      "Iris-virginica\t1.000000\n",
      "Iris-virginica\t1.000000\n",
      "Iris-virginica\t1.000000\n",
      "Iris-virginica\t0.800000\n",
      "Iris-virginica\t1.000000\n"
     ]
    }
   ],
   "source": [
    "#  Load training data\n",
    "data_train = pd.read_csv(\"../data/Iris_train.csv\")\n",
    "# Separate independent variables and dependent variables\n",
    "independent = [\"SepalLengthCm\",\t\"SepalWidthCm\",\t\"PetalLengthCm\",\t\"PetalWidthCm\"]\n",
    "X = data_train[independent]\n",
    "y = data_train[\"Species\"] \n",
    "# Train model\n",
    "clf = my_KNN()\n",
    "clf.fit(X,y)\n",
    "data_test = pd.read_csv(\"../data/Iris_test.csv\")\n",
    "X_test = data_test[independent]\n",
    "# Predict\n",
    "predictions = clf.predict(X_test)\n",
    "# Predict probabilities\n",
    "probs = clf.predict_proba(X_test)\n",
    "# Print results\n",
    "for i,pred in enumerate(predictions):\n",
    "    print(\"%s\\t%f\" % (pred, probs[pred][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
