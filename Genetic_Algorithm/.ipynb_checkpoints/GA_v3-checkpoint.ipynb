{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'my_DT' from 'assignment2.my_DT' (../assignment2/my_DT.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-897b782bd5db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0massignment2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmy_DT\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmy_DT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0massignment8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmy_evaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmy_evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'my_DT' from 'assignment2.my_DT' (../assignment2/my_DT.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pdb import set_trace\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from assignment2.my_DT import my_DT\n",
    "from assignment8.my_evaluation import my_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_GA:\n",
    "    # Tuning with Genetic Algorithm for model parameters\n",
    "\n",
    "    def __init__(self, model, data_X, data_y, decision_boundary, obj_func, generation_size=100, selection_rate=0.5,\n",
    "                 mutation_rate=0.01, crossval_fold=5, max_generation=100, max_life=3):\n",
    "        # inputs:\n",
    "        # model: class object of the learner under tuning, e.g. my_DT\n",
    "        # data_X: training data independent variables (pd.Dataframe)\n",
    "        # data_y: training data dependent variables (pd.Series or list)\n",
    "        # decision_boundary: list of boundaries of each decision variable,\n",
    "        # e.g. decision_boundary = [(\"gini\", \"entropy\"), [1, 16], [0, 0.1]] for my_DT means:\n",
    "        # the first argument criterion can be chosen as either \"gini\" or \"entropy\"\n",
    "        # the second argument max_depth can be any number 1 <= max_depth < 16\n",
    "        # the third argument min_impurity_decrease can be any number 0 <= min_impurity_decrease < 0.1\n",
    "        # obj_func: generate objectives, all objectives are higher the better\n",
    "        # generation_size: number of points in each generation\n",
    "        # selection_rate: percentage of survived points after selection, only affect single objective\n",
    "        # mutation_rate: probability of being mutated for each decision in each point\n",
    "        # crossval_fold: number of fold in cross-validation (for evaluation)\n",
    "        # max_generation: early stopping rule, stop when reached\n",
    "        # max_life: stopping rule, stop when max_life consecutive generations do not improve\n",
    "        \n",
    "        self.model = model\n",
    "        self.data_X = data_X\n",
    "        self.data_y = data_y\n",
    "        self.decision_boundary = decision_boundary\n",
    "        self.obj_func = obj_func\n",
    "        self.generation_size = int(generation_size)\n",
    "        self.selection_rate = selection_rate  # applies only to singe-objective\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossval_fold = int(crossval_fold)\n",
    "        self.max_generation = int(max_generation)\n",
    "        self.max_life = int(max_life)\n",
    "        self.life = self.max_life\n",
    "        self.iter = 0\n",
    "        self.generation = []\n",
    "        self.pf_best = []\n",
    "        self.evaluated = {None: -1}\n",
    "        self.lenGen = 0\n",
    "\n",
    "    def initialize(self):\n",
    "        # Randomly generate generation_size points to self.generation\n",
    "\n",
    "        self.generation = []\n",
    "        \n",
    "        for _ in range(self.generation_size):\n",
    "            x = []\n",
    "            \n",
    "            for decision in self.decision_boundary:\n",
    "                \n",
    "                if type(decision) == list:\n",
    "                    x.append(np.random.random() * (decision[1] - decision[0]) + decision[0])\n",
    "                \n",
    "                else:\n",
    "                    x.append(decision[np.random.randint(len(decision))])\n",
    "            \n",
    "            self.generation.append(tuple(x))\n",
    "            print(x)\n",
    "            set_trace()\n",
    "        ######################\n",
    "        # check if size of generation is correct\n",
    "        \n",
    "        self.lenGen = len(self.generation)\n",
    "        assert (self.lenGen == self.generation_size)\n",
    "        \n",
    "        return self.generation\n",
    "\n",
    "    def evaluate(self, decision):\n",
    "        # Evaluate a certain point\n",
    "        # decision: tuple of decisions\n",
    "        # Avoid repetitive evaluations\n",
    "        \n",
    "        \n",
    "        if decision not in self.evaluated:\n",
    "            \n",
    "            # evaluate with self.crossval_fold fold cross-validation on self.data_X and self.data_y\n",
    "            clf = self.model(*decision)\n",
    "            \n",
    "            # Cross validation:\n",
    "            indices = [i for i in range(len(self.data_y))]\n",
    "            np.random.shuffle(indices)\n",
    "            \n",
    "            size = int(np.ceil(len(self.data_y) / float(self.crossval_fold)))\n",
    "            \n",
    "            objs_crossval = None\n",
    "            \n",
    "            for fold in range(self.crossval_fold):\n",
    "                start = int(fold * size)\n",
    "                \n",
    "                end = start + size\n",
    "                \n",
    "                test_indices = indices[end:]\n",
    "                \n",
    "                train_indices = indices[start:end]\n",
    "                \n",
    "                X_train = self.data_X.loc[train_indices]\n",
    "                X_train.index = range(len(X_train))\n",
    "                \n",
    "                X_test = self.data_X.loc[test_indices]\n",
    "                X_test.index = range(len(X_test))\n",
    "                \n",
    "                y_train = self.data_y.loc[train_indices]\n",
    "                y_train.index = range(len(y_train))\n",
    "                \n",
    "                y_test = self.data_y.loc[test_indices]\n",
    "                y_test.index = range(len(y_test))\n",
    "                \n",
    "                clf.fit(X_train, y_train)\n",
    "                predictions = clf.predict(X_test)\n",
    "                pred_proba = clf.predict_proba(X_test)\n",
    "                actuals = y_test\n",
    "                objs = np.array(self.obj_func(predictions, actuals, pred_proba))\n",
    "                \n",
    "                if type(objs_crossval) == type(None):\n",
    "                    objs_crossval = objs\n",
    "                else:\n",
    "                    objs_crossval += objs\n",
    "\n",
    "            objs_crossval = objs_crossval / float(len(self.data_y))\n",
    "            self.evaluated[decision] = objs_crossval\n",
    "        \n",
    "        return self.evaluated[decision]\n",
    "\n",
    "    def is_better(self, a, b):\n",
    "        # Check if decision a binary dominates decision b\n",
    "        # Return 0 if a == b,\n",
    "        # Return 1 if a binary dominates b,\n",
    "        # Return -1 if a does not binary dominates b.\n",
    "        \n",
    "        if a == b:\n",
    "            return 0\n",
    "        \n",
    "        obj_a = self.evaluate(a)\n",
    "        obj_b = self.evaluate(b)\n",
    "        \n",
    "        if \"write your own code\":\n",
    "            return 1\n",
    "        \n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def compete(self, pf_new, pf_best):\n",
    "        # Compare and merge two pareto frontiers\n",
    "        # If one point y in pf_best is binary dominated by another point x in pf_new\n",
    "        # (exist x and y; self.is_better(x, y) == 1)\n",
    "        # replace that point y in pf_best with the point x in pf_new\n",
    "        # If one point x in pf_new is not dominated by any point y in pf_best (and does not exist in pf_best)\n",
    "        # (forall y in pf_best; self.is_better(y, x) == -1)\n",
    "        # add that point x to pf_best\n",
    "        # Return True if pf_best is modified in the process, otherwise return False\n",
    "        # Write your own code below\n",
    "       \n",
    "        modified = False\n",
    "        \n",
    "        for i in range(len(pf_best)):\n",
    "            \n",
    "            for j in range(len(pf_new)):\n",
    "                \n",
    "                if self.is_better(pf_best[i], pf_new[j]):\n",
    "                    pf_best[i] = pf_new[j]\n",
    "                    pf_new.pop(j)\n",
    "                    modified = True\n",
    "                    break\n",
    "        \n",
    "        to_add = []\n",
    "        \n",
    "        for j in range(len(pf_new)):\n",
    "            not_dominated = True\n",
    "            \n",
    "            for i in range(len(pf_best)):\n",
    "                \n",
    "                if self.is_better(pf_best[i], pf_new[j]):\n",
    "                    not_dominated = False\n",
    "                    break\n",
    "            \n",
    "            if not_dominated:\n",
    "                to_add.append(j)\n",
    "                modified = True\n",
    "        \n",
    "        for j in to_add:\n",
    "            pf_best.append(pf_new[j])\n",
    "        \n",
    "        return modified\n",
    "\n",
    "    def select(self):\n",
    "        # Select which points will survive based on the objectives\n",
    "        # Update the following:\n",
    "        # self.pf = pareto frontier (undominated points from self.generation)\n",
    "        # self.generation = survived points\n",
    "        # single-objective:\n",
    "\n",
    "        if len(self.evaluate(self.generation[0])) == 1:\n",
    "            selected = np.argsort([self.evaluate(x)[0] for x in self.generation])[::-1][\n",
    "                       :int(np.ceil(self.selection_rate * self.generation_size))]\n",
    "            self.pf = [self.generation[selected[0]]]\n",
    "            self.generation = [self.generation[i] for i in selected]\n",
    "\n",
    "        # multi-objective:\n",
    "        else:\n",
    "            self.pf = []\n",
    "            \n",
    "            for x in self.generation:\n",
    "                \n",
    "                if not np.array([self.is_better(y, x) == 1 for y in self.generation]).any():\n",
    "                    self.pf.append(x)\n",
    "            \n",
    "            # remove duplicates\n",
    "            self.pf = list(set(self.pf))\n",
    "            \n",
    "            if len(self.pf) == 1:\n",
    "                self.generation.remove(self.pf[0])\n",
    "                next_pf = []\n",
    "                \n",
    "                for x in self.generation:\n",
    "                    \n",
    "                    if not np.array([self.is_better(y, x) == 1 for y in self.generation]).any():\n",
    "                        next_pf.append(x)\n",
    "                \n",
    "                next_pf = list(set(next_pf))\n",
    "                self.generation = self.pf + next_pf\n",
    "            \n",
    "            else:\n",
    "                self.generation = self.pf[:]\n",
    "                \n",
    "        return\n",
    "\n",
    "    def crossover(self):\n",
    "        # randomly select two points in self.generation\n",
    "        # and generate a new point\n",
    "        # repeat until self.generation_size points were generated\n",
    "        # Write your own code below\n",
    "        def cross(a, b):\n",
    "            new_point = []\n",
    "            for i in range(len(a)):\n",
    "                if \"write your own code\":\n",
    "                    new_point.append(a[i])\n",
    "                else:\n",
    "                    new_point.append(b[i])\n",
    "            return tuple(new_point)\n",
    "\n",
    "        to_add = []\n",
    "        \n",
    "        for _ in range(self.generation_size - len(self.generation)):\n",
    "            ids = np.random.choice(len(self.generation), 2, replace=False)\n",
    "            new_point = cross(self.generation[ids[0]], self.generation[ids[1]])\n",
    "            to_add.append(new_point)\n",
    "        \n",
    "        self.generation.extend(to_add)\n",
    "        \n",
    "        ######################\n",
    "        \n",
    "        # check if size of generation is correct\n",
    "        assert (len(self.generation) == self.generation_size)\n",
    "        \n",
    "        return self.generation\n",
    "\n",
    "    def mutate(self):\n",
    "        # Uniform random mutation:\n",
    "        # each decision value in each point of self.generation\n",
    "        # has the same probability self.mutation_rate of being mutated\n",
    "        # to a random valid value\n",
    "        # write your own code below\n",
    "\n",
    "        for i, x in enumerate(self.generation):\n",
    "            new_x = list(x)\n",
    "            \n",
    "            for j in range(len(x)):\n",
    "                \n",
    "                if np.random.random() < self.mutation_rate:\n",
    "                    decision = self.decision_boundary[j]\n",
    "                    \n",
    "                    if type(decision) == list:\n",
    "                        new_x[j] = np.random.random() * (decision[1] - decision[0]) + decision[0]\n",
    "                    \n",
    "                    else:\n",
    "                        new_x[j] = decision[np.random.randint(len(decision))]\n",
    "            \n",
    "            self.generation[i] = tuple(new_x)\n",
    "        \n",
    "        return self.generation\n",
    "\n",
    "    def tune(self):\n",
    "        # Main function of my_GA Stop when self.iter == self.max_generation or self.life == 0 Return the best pareto\n",
    "        # frontier pf_best (list of decisions that never get binary dominated by any candidate evaluated)\n",
    "        \n",
    "        self.initialize()\n",
    "        \n",
    "        while self.life > 0 or self.iter < self.max_generation:\n",
    "            self.select()\n",
    "            \n",
    "            if self.compete(self.pf, self.pf_best):\n",
    "                self.life = self.max_life\n",
    "            \n",
    "            else:\n",
    "                self.life -= 1\n",
    "            self.iter += 1\n",
    "            self.crossover()\n",
    "            self.mutate()\n",
    "        \n",
    "        return self.pf_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "\n",
    "def obj_func1(predictions, actuals, pred_proba=None):\n",
    "    # Two objectives: higher recall and higher precision\n",
    "    eval = my_evaluation(predictions, actuals, pred_proba)\n",
    "    return [eval.recall(), eval.precision()]\n",
    "\n",
    "\n",
    "def obj_func2(predictions, actuals, pred_proba=None):\n",
    "    # One objectives: higher f1 score\n",
    "    eval = my_evaluation(predictions, actuals, pred_proba)\n",
    "    return [eval.f1()]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load training data\n",
    "    data_train = pd.read_csv(\"../data/Iris_train.csv\")\n",
    "    # Separate independent variables and dependent variables\n",
    "    independent = [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]\n",
    "    X = data_train[independent]\n",
    "    y = data_train[\"Species\"]\n",
    "    # Multi-objective\n",
    "    ga = my_GA(my_DT, X, y, [(\"gini\", \"entropy\"), [1, 16], [0, 0.1]], obj_func1, generation_size=10, crossval_fold=2,\n",
    "               max_generation=10, max_life=2)\n",
    "    frontier = ga.tune()\n",
    "    objs = [ga.evaluate(decision) for decision in frontier]\n",
    "    print(objs)\n",
    "    # Single objective\n",
    "    ga2 = my_GA(my_DT, X, y, [(\"gini\", \"entropy\"), [1, 16], [0, 0.1]], obj_func2, generation_size=10, crossval_fold=2,\n",
    "                max_generation=10, max_life=2)\n",
    "    best = ga2.tune()\n",
    "    print(ga2.evaluate(best[0]))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
