{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from pdb import set_trace\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-86c453dd26bb>, line 82)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-86c453dd26bb>\"\u001b[0;36m, line \u001b[0;32m82\u001b[0m\n\u001b[0;31m    Update wi\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class my_AdaBoost:\n",
    "\n",
    "    def __init__(self, base_estimator = None, n_estimators = 50):\n",
    "        # base_estimator: the base classifier class, e.g. my_DT\n",
    "        # n_estimators: # of base_estimator rounds\n",
    "        self.base_estimator = base_estimator\n",
    "        self.n_estimators = int(n_estimators)\n",
    "        self.estimators = [deepcopy(self.base_estimator) for i in range(self.n_estimators)]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # X: pd.DataFrame, independent variables, float\n",
    "        # y: list, np.array or pd.Series, dependent variables, int or str\n",
    "        self.classes_ = list(set(list(y)))\n",
    "        #print(self.classes_)\n",
    "        \n",
    "        k = len(self.classes_)\n",
    "        #print(k)\n",
    "        \n",
    "        n = len(y)\n",
    "        #print(n)\n",
    "        \n",
    "        w = np.array([1.0 / n] * n)\n",
    "        #print(w)\n",
    "        #print(len(w))\n",
    "        \n",
    "        labels = np.array(y)\n",
    "        #print(labels)\n",
    "        \n",
    "        self.alpha = []\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            # Sample with replacement from X, with probability w\n",
    "            sample = np.random.choice(n, n, p=w)\n",
    "            #print(sample)\n",
    "            \n",
    "            # Train base classifier with sampled training data\n",
    "            sampled = X.iloc[sample]\n",
    "            #print(sampled)\n",
    "            \n",
    "            sampled.index = range(len(sample))\n",
    "            #print(sampled.index)\n",
    "            #print(labels[sample])\n",
    "            \n",
    "            self.estimators[i].fit(sampled, labels[sample])\n",
    "            \n",
    "            predictions = self.estimators[i].predict(X)\n",
    "            #print(predictions)\n",
    "            \n",
    "            diffs = np.array(predictions) != y\n",
    "            #print(len(diffs))\n",
    "            \n",
    "            # Compute error rate and alpha for estimator i\n",
    "            error = np.sum(diffs * w)\n",
    "            #print(error)\n",
    "            #print(1 - 1.0 / k)\n",
    "            \n",
    "            while error >= (1 - 1.0 / k):\n",
    "                w = np.array([1.0 / n] * n)\n",
    "                \n",
    "                sample = np.random.choice(n, n, p=w)\n",
    "                \n",
    "                # Train base classifier with sampled training data\n",
    "                sampled = X.iloc[sample]\n",
    "                \n",
    "                sampled.index = range(len(sample))\n",
    "                \n",
    "                self.estimators[i].fit(sampled, labels[sample])\n",
    "                \n",
    "                predictions = self.estimators[i].predict(X)\n",
    "                #print(predictions)\n",
    "                \n",
    "                diffs = np.array(predictions) != y\n",
    "                # Compute error rate and alpha for estimator i\n",
    "                \n",
    "                error = np.sum(diffs * w)\n",
    "            \n",
    "            # Compute alpha for estimator i\n",
    "            EPS = 1e-10\n",
    "            self.alpha.append(np.log(k - 1) + (np.log((1 - error) / (error + EPS))))\n",
    "            #print(-self.alpha[-1])\n",
    "\n",
    "            Update wi\n",
    "            for i in range(n):\n",
    "                if(diffs[i]):\n",
    "                    w[i] *= np.exp(self.alpha[-1])\n",
    "                else:\n",
    "                    w[i] = w\n",
    "                    \n",
    "            for i in range(n):\n",
    "                if(diffs[i]):\n",
    "                    w[i] = w\n",
    "                else:\n",
    "                    w[i] *= np.exp(self.alpha[-1])\n",
    "                   \n",
    "                    \n",
    "                    \n",
    "                \n",
    "            \n",
    "            #normalisation\n",
    "            w = w / np.sum(w)\n",
    "            #print(np.sum(w))\n",
    "            #print(w)\n",
    "\n",
    "        # Normalize alpha\n",
    "        self.alpha = self.alpha / np.sum(self.alpha)\n",
    "#         print(self.alpha)\n",
    "#         print(w)\n",
    "#         print(error)\n",
    "#         print(predictions)\n",
    "#         print(self.estimators)\n",
    "        return\n",
    "\n",
    "    def predict(self, X):\n",
    "        # X: pd.DataFrame, independent variables, float\n",
    "        # return predictions: list\n",
    "        probs = self.predict_proba(X)\n",
    "        predictions = [self.classes_[np.argmax(prob)] for prob in probs.to_numpy()]\n",
    "        #print(predictions)\n",
    "        return predictions\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # X: pd.DataFrame, independent variables, float\n",
    "        # prob: what percentage of the base estimators predict input as class C\n",
    "        # prob(x)[C] = sum(alpha[j] * (base_model[j].predict(x) == C))\n",
    "        # return probs = pd.DataFrame(list of prob, columns = self.classes_)\n",
    "        # write your code below\n",
    "        \n",
    "        probs = {}\n",
    "        \n",
    "        p = 1\n",
    "        \n",
    "        X_cols_vals = X[X.columns]\n",
    "        #print(X_cols_vals)\n",
    "        \n",
    "        \n",
    "        for label in self.classes_:\n",
    "            for i in range(self.n_estimators):\n",
    "                probs[label] = (self.alpha[i] * ((self.estimators[i].predict(X)) == label))\n",
    "        \n",
    "        for labels_i,values_i in probs.items():\n",
    "            probs[labels_i] = np.argmax(np.sum(probs[labels_i][values_i]))\n",
    "                \n",
    "                    \n",
    "#         for label in self.classes_:\n",
    "#             for i in range(self.n_estimators): #true =1 false = 0\n",
    "#                 result = ((self.estimators[i].predict(X)) == label).astype(int)\n",
    "#                 result[result == 0] = -1\n",
    "#                 #print((result))\n",
    "#                 for j in range(len(result)):\n",
    "#                     probs[label] = (self.alpha[i] * result)\n",
    "                        \n",
    "                #probs[label] = (self.alpha[i] * ((self.estimators[i].predict(X)) == label))\n",
    "                #probs[label] = (self.alpha[i] * (result))\n",
    "            \n",
    "        probs = pd.DataFrame(probs, columns=self.classes_)\n",
    "        #probs = pd.Series(probs).to_frame(self.classes_)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f6fedbe94b91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#  Load training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/Iris_train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Separate independent variables and dependent variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mindependent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"SepalLengthCm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SepalWidthCm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"PetalLengthCm\"\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0;34m\"PetalWidthCm\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindependent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#  Load training data\n",
    "data_train = pd.read_csv(\"../data/Iris_train.csv\")\n",
    "# Separate independent variables and dependent variables\n",
    "independent = [\"SepalLengthCm\",\t\"SepalWidthCm\",\t\"PetalLengthCm\",\t\"PetalWidthCm\"]\n",
    "X = data_train[independent]\n",
    "y = data_train[\"Species\"]\n",
    "# Train model\n",
    "base_estimator = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 1)\n",
    "clf = my_AdaBoost(base_estimator=base_estimator, n_estimators = 50)\n",
    "clf.fit(X, y)\n",
    "# Load testing data\n",
    "data_test = pd.read_csv(\"../data/Iris_test.csv\")\n",
    "X_test = data_test[independent]\n",
    "# Predict\n",
    "predictions = clf.predict(X_test)\n",
    "#print(predictions)\n",
    "# Predict probabilities\n",
    "probs = clf.predict_proba(X_test)\n",
    "# Print results\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(\"%s\\t%f\" % (pred, probs[pred][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
